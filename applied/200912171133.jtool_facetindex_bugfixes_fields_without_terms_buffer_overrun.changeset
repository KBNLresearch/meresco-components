diff --unidirectional-new-file --exclude=.svn --exclude='*.pyc' --exclude=applied --recursive --unified version_2.23.1_with_oai/merescocomponents/facetindex/_docsetlist.cpp trunk/merescocomponents/facetindex/_docsetlist.cpp
--- version_2.23.1_with_oai/merescocomponents/facetindex/_docsetlist.cpp	2009-12-16 16:30:47.000000000 +0100
+++ trunk/merescocomponents/facetindex/_docsetlist.cpp	2009-12-15 14:26:58.000000000 +0100
@@ -27,6 +27,7 @@
  * end license */
 
 #include <gcj/cni.h>
+#include "java/lang/Object.h"
 #include "org/apache/lucene/index/TermEnum.h"
 #include "org/apache/lucene/index/Term.h"
 
@@ -437,37 +438,36 @@
 }
 
 DocSetList* DocSetList_forField(lucene::index::IndexReader* reader, char* fieldname, IntegerList *mapping) {
-    //printf("DocSetList_forField 1\n");
     DocSetList* list = DocSetList_create();
-    jstring field = NULL;
+    jstring field = JvNewStringUTF(fieldname);
     lucene::index::TermEnum* termEnum =
-        reader->terms(new lucene::index::Term(JvNewStringUTF(fieldname), JvNewStringUTF("")));
-    //("DocSetList_forField 2\n");
+        reader->terms(new lucene::index::Term(field, JvNewStringUTF("")));
+    lucene::index::Term* term = termEnum->term();
+    if (!term || !term->field()->equals((java::lang::Object*) field)) {
+        return list;
+    }
+    field = term->field();
     do {
         lucene::index::Term* term = termEnum->term();
         if (!term) {
             break;
         }
-        if (!field) {
-            field = term->field();
-        }
-        else if (term->field() != field) {
+        if (field != term->field()) {
             break;
         }
-        //("DocSetList_forField 3\n");
 
         jstring termText = term->text();
 
-        char cTermText[2000];
-        int w = JvGetStringUTFRegion(termText, 0, termText->length(), cTermText);
+        int jTermTextLength = termText->length();
+        char* cTermText = (char*) malloc(jTermTextLength * 4 + 1);
+        int w = JvGetStringUTFRegion(termText, 0, jTermTextLength, cTermText);
         cTermText[w] = '\0';
 
-        //("DocSetList_forField 4\n");
         fwPtr ds = DocSet::forTerm(reader, fieldname, cTermText, mapping);
         list->addDocSet(ds, cTermText);
-        //("DocSetList_forField 5\n");
+
+        free(cTermText);
     } while (termEnum->next());
-    //("DocSetList_forField 6\n");
     return list;
 }
 
diff --unidirectional-new-file --exclude=.svn --exclude='*.pyc' --exclude=applied --recursive --unified version_2.23.1_with_oai/merescocomponents/facetindex/__init__.py trunk/merescocomponents/facetindex/__init__.py
--- version_2.23.1_with_oai/merescocomponents/facetindex/__init__.py	2009-12-16 16:30:47.000000000 +0100
+++ trunk/merescocomponents/facetindex/__init__.py	2009-12-15 14:26:58.000000000 +0100
@@ -44,5 +44,6 @@
 from trie import Trie
 from cql2lucenequery import CQL2LuceneQuery
 from fields2lucenedocument import Fields2LuceneDocumentTx
+from clausecollector import ClauseCollector
 import merescolucene
 
diff --unidirectional-new-file --exclude=.svn --exclude='*.pyc' --exclude=applied --recursive --unified version_2.23.1_with_oai/merescocomponents/facetindex/lucene.py trunk/merescocomponents/facetindex/lucene.py
--- version_2.23.1_with_oai/merescocomponents/facetindex/lucene.py	2009-12-16 16:30:47.000000000 +0100
+++ trunk/merescocomponents/facetindex/lucene.py	2009-12-15 14:26:58.000000000 +0100
@@ -48,10 +48,6 @@
 class LuceneException(Exception):
     pass
 
-class IncludeStopWordAnalyzer(object):
-    def tokenStream(self, fieldName, reader):
-        return LowerCaseFilter(StandardFilter(StandardTokenizer(reader)))
-
 class _Logger(object):
     def comment(self, *strings):
         self.writeLine('# ', *strings)
diff --unidirectional-new-file --exclude=.svn --exclude='*.pyc' --exclude=applied --recursive --unified version_2.23.1_with_oai/test/alltests.py trunk/test/alltests.py
--- version_2.23.1_with_oai/test/alltests.py	2009-12-16 16:30:59.000000000 +0100
+++ trunk/test/alltests.py	2009-12-15 14:26:58.000000000 +0100
@@ -62,6 +62,7 @@
 
 from facetindex.incrementalindexingtest import IncrementalIndexingTest
 from facetindex.integerlisttest import IntegerListTest
+from facetindex.clausecollectortest import ClauseCollectorTest
 
 from ngram.ngramtest import NGramTest
 from ngram.ngramquerytest import NGramQueryTest
diff --unidirectional-new-file --exclude=.svn --exclude='*.pyc' --exclude=applied --recursive --unified version_2.23.1_with_oai/test/facetindex/clausecollectortest.py trunk/test/facetindex/clausecollectortest.py
--- version_2.23.1_with_oai/test/facetindex/clausecollectortest.py	1970-01-01 01:00:00.000000000 +0100
+++ trunk/test/facetindex/clausecollectortest.py	2009-12-15 14:26:54.000000000 +0100
@@ -0,0 +1,46 @@
+# -*- coding: utf-8 -*-
+## begin license ##
+#
+#    Meresco Components are components to build searchengines, repositories
+#    and archives, based on Meresco Core.
+#    Copyright (C) 2007-2009 SURF Foundation. http://www.surf.nl
+#    Copyright (C) 2007-2009 Kennisnet http://www.kennisnet.nl
+#    Copyright (C) 2009 Delft University of Technology http://www.tudelft.nl
+#    Copyright (C) 2009 Tilburg University http://www.uvt.nl
+#    Copyright (C) 2007-2009 Seek You Too (CQ2) http://www.cq2.nl
+#
+#    This file is part of Meresco Components.
+#
+#    Meresco Components is free software; you can redistribute it and/or modify
+#    it under the terms of the GNU General Public License as published by
+#    the Free Software Foundation; either version 2 of the License, or
+#    (at your option) any later version.
+#
+#    Meresco Components is distributed in the hope that it will be useful,
+#    but WITHOUT ANY WARRANTY; without even the implied warranty of
+#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+#    GNU General Public License for more details.
+#
+#    You should have received a copy of the GNU General Public License
+#    along with Meresco Components; if not, write to the Free Software
+#    Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+#
+## end license ##
+from merescocomponents.facetindex import ClauseCollector
+from cq2utils import CQ2TestCase
+from cqlparser import parseString
+
+class ClauseCollectorTest(CQ2TestCase):
+    def setUp(self):
+        CQ2TestCase.setUp(self)
+
+    def testClauseCollector(self):
+        self.assertEquals(['cat', 'dog'], self.findClauses("cat or dog"))
+        self.assertEquals(['cat', 'dog'], self.findClauses("(cat or dog)"))
+        self.assertEquals(['cat', 'dog', 'horse'], self.findClauses("(cat or dog) not horse"))
+
+    def findClauses(self, cql):
+        clauses = []
+        ClauseCollector(parseString(cql), logger=lambda clause: clauses.append(clause)).visit()
+        return clauses
+
diff --unidirectional-new-file --exclude=.svn --exclude='*.pyc' --exclude=applied --recursive --unified version_2.23.1_with_oai/test/facetindex/docsetlisttest.py trunk/test/facetindex/docsetlisttest.py
--- version_2.23.1_with_oai/test/facetindex/docsetlisttest.py	2009-12-16 16:30:47.000000000 +0100
+++ trunk/test/facetindex/docsetlisttest.py	2009-12-15 14:26:54.000000000 +0100
@@ -30,6 +30,7 @@
 from merescocomponents.facetindex import DocSetList, DocSet
 from merescocomponents.facetindex.docsetlist import JACCARD_ONLY, JACCARD_MI
 from merescocomponents.facetindex.triedict import TrieDict
+from merescocomponents.facetindex.merescolucene import IndexReader
 from lucenetestcase import LuceneTestCase
 from cq2utils import MATCHALL
 
@@ -201,6 +202,14 @@
         self.assertEquals(('t€rm0', NA), cs.next())
         self.assertEquals(('t€rm1', NA), cs.next())
 
+    def testForFieldEmptyIndex(self):
+        self.createSimpleIndexWithEmptyDocuments(0)
+        self.assertEquals(0, len(DocSetList.forField(self.reader, 'aField')))
+
+    def testForFieldNotIndexed(self):
+        self.createBigIndex(4, 5)
+        self.assertEquals(0, len(DocSetList.forField(self.reader, 'field')))
+
     #def testAppendToRow(self):
     def testAppendDocument(self):
         docsetlist = DocSetList()
@@ -555,7 +564,7 @@
             self.fail()
         except ValueError, e:
             self.assertEquals('maxTermFreqPercentage must be >0 and <=100 (0)', str(e))
-    
+
     def testSortingOnCardinalityDoesNotRuinTermLookup(self):
         ds0 = DocSet([1,2])
         ds1 = DocSet([1,2,3])

.. -*- coding: utf-8 -*-
.. This documentation is written using reStructuredText. See http://docutils.sf.net
.. include:: <isogrk1.txt>

-----------------------
Clustering with Meresco
-----------------------

:Authors: Seek You Too
:Organization: `Seek You Too`_
:Version: 0.1
:Copyright: 2009 by Seek You Too
:License: |by-nc-nd|_ Attribution-Noncommercial-No Derivative Works 3.0 License

.. _`Seek You Too`: http://www.cq2.nl
.. |by-nc-nd| image:: http://i.creativecommons.org/l/by-nc-nd/3.0/88x31.png
    :alt:
.. _by-nc-nd: http://creativecommons.org/licenses/by-nc-nd/3.0/

.. meta::
    :Revision: $LastChangedRevision: 1226 $
    :Date: $LastChangedDate: 2009-01-07 09:48:42 +0000 (Wed, 07 Jan 2009) $
    :LastChangedBy: $LastChangedBy: ejgroene $


:Document History:

    * 2008-08-12,   E.J. Groeneveld (CQ2),  version 0.1,    Initial version


.. contents:: Table of Contents
.. section-numbering::


.. |X2| replace:: |khgr|\ `2`:superscript:

Introduction
============

This document describes Clustering with Meresco. As there are many ways to do clustering, and there is also debate about what should be called clustering and what not, it is good to know that clustering with Meresco is based on the following assumptions:

    * When is clustered: during queries; there is no training
    * What is clustered: the search results
    * What is the goal: to support better navigation.
    * How is clustered: clusters are based on single features (keywords), which are also labels
    * What algoritms are used: clustering uses `Jaccard`, `Mutual Information` (MI, also known as `Information Gain`) and |X2|.

This means that clustering is provided by adding clustering to the part of the DNA that handles queries.  The data provided by the clustering algoritms can be used to create HTML pages or XML responses.  The latter is not covered here.

For any application of clustering, you will have to tune the specific parameters as mentioned in the tuning chapter.  Meresco Clustering can deliver very good results, even for dirty and biased data-sets, but only with proper tuning.  Without tuning, you will be disappointed.


Configuring Clustering using DNA
============================================

The Clustering functionality is offered by the Drilldown component.  Clustering is possible on any field for which the drilldown component is configured.  For example, clustering on the field ``dc.subject``, with the results formatted in HTML using the DynamicHtml component, one would write the DNA as follows:

::

    (DynamicHtml(['/templates'], reactor=reactor, indexPage='/search'),
        Drilldown(['dc.subject'])
    )

Then, from within the ``DynamicHtml`` templates (and any other component to which the ``Drilldown`` component is listening), one can call the method:

::

    clusters = any.jaccard(docset, [('mods', 7, 20)]))

The parameter ``docset`` is a ``DocSet`` object, usually obtained by calling ``any.docsetFromQuery(query)``.  Thus, the clusters are calculated based on the results of a query.  The details about the ``jaccard()`` method's return value and its parameters are outlined below.

Drilldown.jaccard()
===================

The ``jaccard()`` method is most similar to the ``drilldown()`` method with regard to the parameters and the return value.  Additional parameters allow for tuning the algoritms.

Clustering is done in two steps:

    1. First a preselection of possible clusters is calculated with the Jaccard algoritm.
    2. Secondly, the preselection is post-processed using one of three secondary algoritms:
        1. Term Frequency
        2. |X2|
        3. Mutual Information (MI, or Information Gain)

Parameters
----------
``docset`` is an ``DocSet`` object as returned from ``docsetFromQuery()``.  The docset is a filter of relevant documents to be used for the clustering.  Only documents that are in this docset are considered during the algoritm evaluation, and only documents in this docset are returned.

* ``jaccardFieldsAndRanges`` is an iterable of tuples contaning `field`, jaccard `lowerbound` and jaccard `upperbound`.

    * The `field` is the name of a field that has been configured for drilldown.  Clustering will take place using features (keywords) from this field only.

    * The Jaccard `lowerbound` is a percentage below which clusters are to be ignored.  This parameter determines the size of the preselection.  Take this too low, and the performance will degrade quickly. Generally values of 5 and higher yield very good performance and good results.

    * The Jaccard `upperbound` is a percentage above which clusters are to be ignored.  This parameter has only a modest impact on performance as it does not reduce the initial preselection, but it only reduces the number of features for evaluation with the secondary algoritm.  Using an upper limit avoids synomyms being selected as clusters.

* ``algorithm`` is the id of the secondary algoritm to be used after the preselection has been calculated.  The preselection is always calculated with the `Jaccard similarity coefficient`.  Possible values for `algoritm` are:

    * ``JACCARD_MI`` - This is the default.  The preselection will be both narrowed down and sorted based on the `Mutual Information` algoritm.  This algoritm is also known as `Information Gain`.

    * ``JACCARD_X2`` - The preselection will be both narrowed down and sorted based on the |X2| algoritm.

    * ``JACCARD_ONLY`` - The preselection will not be narrowed down, but it will be sorted on term frequency.

These algoritms are well known in the literature and described for example in `Introduction to Information Retrieval`, Manning et.al, Cambridge University Press, 2008.


Return value
------------

The ``jaccard()`` method returns an generator with the results, if any, for each requested field.  The results for each field consists of a tuple with the name of the field and the clusters: ``(fieldname, clusters)``.  The ``clusters`` is again a generator with a tuple for each feature (term) and its Jaccard, MI or |X2| value as requested.  If we take for example:

::

    clusters = any.jaccard(docset, [('dc.subject', 10, 25), ('mods', 7, 20)]))

and we make a list from the generator it returns by ``list(clusters)``, we get:

::

    [('dc.subject', <generator>), ('mods'), <generator>)]

if we then make a list from the first generator beloning to the field ``dc.subject``, we'll get for example:

::

    [('nuclear', 89), ('supply', 76), ('agency', 65), ('solar', 56)]

These are the results for a query on ``energy`` on a raw dataset from Delft University Library.

The numbers attached to each feature or term depend on the secondary algoritm.  The features or terms are sorted according to this number:

    * If the algoritm is `MI`, then the number is the `MI` for the set of documents containing the term and the set of documents as represented by the input docset.  This often small number is multiplied by 10.000 and returned as an integer. ```NOTE``` With `MI`, only terms with an absolute value of less than 0.5 are included in the output.  Sorting is on decreasing MI.

    * With |X2| the |X2| valeu for same document sets as `MI` is returned, rounded to an integer value.  Sorting is on decreasing |X2|.

    * With `jaccard` only, the `jaccard index`, as a percentage, is returned, rounded to an integer value.  Sorting is on `increasing` Jaccard.


Tuning
======
The most important prerequisite for succesful tuning is a realistic dataset.  It must represent the production set as much as possible and it is recommend to just copy a production set.

Then find a few good examples for tuning your clusters.  For example the algoritms behave very differently on the collection used as an example for words like 'water', 'energy' and 'computer'.  What worked well for 'water' may not work for 'energy' and so on.  It is really important to pick your test set well and `keep extending it while in the process of tuning` as long as you find new suspects.

There are several tuning parameters:
    1. The `collection` of terms (features).  Configure this by creating an index and add this index to the Drilldown component.  Then use this index in the call to ``jaccard()``.
    2. The Jaccard `lowerbound`.  This determines the lowest Jaccard value that is included in the preselection.  Good values lay in the range 5 to 15.  Lower values significantly increase the preselection and the time taken by the secondary algoritm.
    3. The Jaccard `upperbound`.  This determines the highest Jaccard value that is post-processed by the secondary algoritm.  Good values lay in the range 25 and upward.
    4. Cut-off `first N` results.  From the results returned by ``jaccard()``, cut-off at a number of at most N features (terms).  Use ``itertools.islice()`` for example.
    5. Cut-off with `threshold`.  From the results returned by ``jaccard()``, cut-off when the Jaccard, MI or |X2| exeeds a certain threshold.  Use ``itertools.takewhile()`` for example. Note that the sorting is different depending on the secondary algoritm being used.